{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d84e9d-7035-456a-ba90-53e6eb50306d",
   "metadata": {},
   "source": [
    "## This nb borrowed lines from fastai, OpenAI & ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff34ba2e-329b-417e-a8e4-c32077a93aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d8eba6-0cb1-4b2b-a28c-e80424012298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from miniai.imports import *\n",
    "from miniai.datasets import *\n",
    "from datasets import load_dataset,load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b224b5-946e-4a51-91de-6ae5b786349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59c0c18-47a2-478b-b15c-77eda169fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of GPUs available =  1\n"
     ]
    }
   ],
   "source": [
    "class GPUCUDAMissing(BaseException):\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        print('# of GPUs available = ', torch.cuda.device_count())\n",
    "    else:\n",
    "        raise GPUCUDAMissing\n",
    "except GPUCUDAMissing:\n",
    "    print(\"ERROR: GPU is missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fdc6c4-776d-4259-ab47-5a7009bec5dc",
   "metadata": {},
   "source": [
    "### Loading Tiny-Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5021c4-9df1-4793-8e55-7151982ec4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"zh-plus/tiny-imagenet\"\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48387d54-3fbe-49fd-90f5-1c8872835683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f8166-918c-4ca7-a783-cfe8dd28b10e",
   "metadata": {},
   "source": [
    "### Cutdown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934c40cc-d1a2-4735-a1fd-d7411fdcd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_equally(vector, items_per_category, items_to_select):\n",
    "    total_items = len(vector)\n",
    "    idx = []\n",
    "    for category_start in range(0, total_items, items_per_category):\n",
    "        idx.extend(range(category_start, category_start + items_to_select))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f653d785-0b93-4f96-b73e-c4fa247ec500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbls_t = np.array(dsd['train']['label'])\n",
    "idx_t = slice_equally(lbls_t, items_per_category = 500, items_to_select = 50)\n",
    "#npvector[idx_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5a133f-6bb9-41b7-81f4-c8a5b7b010cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_v = np.array(dsd['valid']['label'])\n",
    "idx_v = slice_equally(lbls_v, items_per_category = 50, items_to_select = 20)\n",
    "#npvector[idx_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb4ed19-b206-4c8b-a256-eb8399de89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd['train'] = dsd['train'].select(idx_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da268a4-5e4a-4cbc-a58a-4146503ad93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd['valid'] = dsd['valid'].select(idx_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa3561a-7296-47ed-bb1b-73b2539a3be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13eeddce-48b5-491d-adc7-31da319fe9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[xl] = [(torch.ones([3,1,1])*(TF.to_tensor(o)-0.0)) for o in b[xl]]\n",
    "\n",
    "bs = 32\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=7)\n",
    "dt = dls.train\n",
    "xb,yb = next(iter(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300aae2-b5e8-46d7-b704-931c4c6513b7",
   "metadata": {},
   "source": [
    "### Generate captions for CLIP to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f566bd-e6df-4e55-8c0f-e257c8b21e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "fp_json_pos2idx = hf_hub_download(repo_id=name, filename=\"dataset_infos.json\", repo_type=\"dataset\")\n",
    "fp_idx2human = hf_hub_download(repo_id=name, filename=\"classes.py\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4155fa3d-af77-445c-8c9e-5b27a3161a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(fp_json_pos2idx,) \n",
    "data_pos2idx = json.load(f) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd41d7f-d5e8-4c8a-b60c-9a788ae539ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo provided a variable called 'i2d'\n",
    "exec(open(fp_idx2human).read()) \n",
    "# Let's rename this variable to something suitable for this notebook\n",
    "idx2human = i2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3373a79-fc63-41ab-9dd2-28c360340292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2idx = data_pos2idx['Maysee--tiny-imagenet']['features']['label']['names']\n",
    "pos2human = [idx2human[v] for k,v in enumerate(pos2idx)]\n",
    "captions = [\"A photo of a \" + txt.split(\",\")[0] for txt in pos2human]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb141f5b-de65-436a-8bc4-5a092f3e8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clipmodel = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "#processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1c6fe-9030-4ba5-bd99-52f9003c7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c295b19-c841-4fa6-ac5a-0269c9f5a68c",
   "metadata": {},
   "source": [
    "Optional: Use the cmd below to determine if VM-Container is paging while loading these models\n",
    "\n",
    "apt update && apt-get install sysstat && pidstat -r -d --human 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704c92e2-baf1-4574-bca0-5f8b6a2dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_images(xb[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d664887-222f-4bfa-9391-5fc9595440ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c25a8-e0ff-4d8f-9911-8becd5f8c3ff",
   "metadata": {},
   "source": [
    "### CLIP: (img, text) -> (img_emb, text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e93ca97-f0a1-473e-9cfd-99ffb0b731fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=captions, images=xb, return_tensors=\"pt\", padding=True, do_rescale=False)\n",
    "image_input = inputs[\"pixel_values\"].to(\"cuda\")\n",
    "text_inputs = inputs[\"input_ids\"].to(\"cuda\")\n",
    "attention_mask = inputs[\"attention_mask\"].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92123b0e-b3bf-4a5e-9bb9-22aad45126ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Compute the image and text embeddings\n",
    "    image_features = clipmodel.get_image_features(image_input)\n",
    "    text_features = clipmodel.get_text_features(input_ids=text_inputs, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8657517a-4200-4e6e-811a-56b73fb56958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), torch.Size([200, 512]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape, text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363db431-7f3e-40ff-a39c-c8fe658a79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd704cac-660d-49cd-9d50-e8f6f89197fd",
   "metadata": {},
   "source": [
    "### Pass img_features to SD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b5a704-5fd0-414f-872c-f0143307c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def abar(t): return (t*math.pi/2).cos()**2\n",
    "def inv_abar(x): return x.sqrt().acos()*2/math.pi\n",
    "\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.rand(n,).to(x0).clamp(0,0.999)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    abar_t = abar(t).reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = abar_t.sqrt()*x0 + (1-abar_t).sqrt()*ε\n",
    "    return (xt, t.to(device)), ε\n",
    "\n",
    "def collate_ddpm(b): return noisify(default_collate(b)[xl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981aff3-7eee-4a79-bb91-5b491998ea8b",
   "metadata": {},
   "source": [
    "Info: In order to fix some CUDA multiprocessing issue which I don't understand. Please set num_workers=0 as shown in the cell below. Source: https://github.com/pytorch/pytorch/issues/40403#issuecomment-731782611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31c80df-ce8c-47c8-ad65-988e7b074430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_ddpm(ds): return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53153150-4670-4797-ae8b-8efdf7cfc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ddpm(b):\n",
    "    #import pdb; pdb.set_trace()    \n",
    "    b = default_collate(b)\n",
    "    #(xt,t),eps = noisify(b[xl])       # original line from Jeremy\n",
    "    \n",
    "    # ok, let's do the padding and shifting the range from (0,1) to (-0.5,0.5) for SD\n",
    "    b_padded_n_shifted = F.pad(b[xl], (0,0,0,0))-0.5\n",
    "    (xt,t),eps = noisify(b_padded_n_shifted)\n",
    "    \n",
    "    # Below are lines for CLIP\n",
    "    inputs = processor(images=b[xl], return_tensors=\"pt\", padding=True, do_rescale=False).to(\"cuda\")\n",
    "    image_input = inputs[\"pixel_values\"]\n",
    "    with torch.no_grad():\n",
    "        image_features = clipmodel.get_image_features(image_input)\n",
    "    return (xt,t,image_features),eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c18232-8c90-486f-a1bb-5cad881dd68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[xl] = [ (torch.ones([3,1,1])*TF.to_tensor(o)) for o in b[xl]] # some images have 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9a866e1-913b-4bac-9df8-99d8f7aec325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0f8eda8-dd11-4b97-a031-0e9e96cba045",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['valid']))\n",
    "\n",
    "dl = dls.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc422cb4-24cf-4149-b2b6-c7b3902f4dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 115 ms, total: 1.45 s\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(xt,t,image_features),eps = b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56dbc237-0007-40cd-8c82-92170420e7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 64, 64]),\n",
       " torch.Size([32]),\n",
       " torch.Size([32, 512]),\n",
       " torch.Size([32, 3, 64, 64]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape, t.shape, image_features.shape, eps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c4b30-ecd6-4680-8aa8-c71f1809e840",
   "metadata": {},
   "source": [
    "### Build Conditional UNet from Lecture 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b3cbe-53a4-47a2-8288-779ba654a350",
   "metadata": {},
   "source": [
    "# Diffusion unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "553b2ef1-f41c-4d49-ad92-42b582f4d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d806531-5ac6-4ff9-bb14-2376ac7ed3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from miniai.imports import *\n",
    "\n",
    "from einops import rearrange\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d68bcb1e-47fa-4082-b85c-92eb28ae4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "mpl.rcParams['figure.dpi'] = 70\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "if fc.defaults.cpus>8: fc.defaults.cpus=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30c6c6-c5ba-454e-b970-fe373d051de8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b77ce0a-15b6-49e2-94ed-938530532a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def timestep_embedding(tsteps, emb_dim, max_period= 10000):\n",
    "    exponent = -math.log(max_period) * torch.linspace(0, 1, emb_dim//2, device=tsteps.device)\n",
    "    emb = tsteps[:,None].float() * exponent.exp()[None,:]\n",
    "    emb = torch.cat([emb.sin(), emb.cos()], dim=-1)\n",
    "    return F.pad(emb, (0,1,0,0)) if emb_dim%2==1 else emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d28ba08-48f6-4a5e-b023-16119bf709d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pre_conv(ni, nf, ks=3, stride=1, act=nn.SiLU, norm=None, bias=True):\n",
    "    layers = nn.Sequential()\n",
    "    if norm: layers.append(norm(ni))\n",
    "    if act : layers.append(act())\n",
    "    layers.append(nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca7f565e-aeea-498d-a592-7859e930dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def upsample(nf): return nn.Sequential(nn.Upsample(scale_factor=2.), nn.Conv2d(nf, nf, 3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f1e5204-011f-47f7-a467-410c218a688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lin(ni, nf, act=nn.SiLU, norm=None, bias=True):\n",
    "    layers = nn.Sequential()\n",
    "    if norm: layers.append(norm(ni))\n",
    "    if act : layers.append(act())\n",
    "    layers.append(nn.Linear(ni, nf, bias=bias))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beb788d0-26f0-40ca-a0ac-e1ae8591ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is giving poor results - use the cell below instead\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, ni, attn_chans):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(ni, ni//attn_chans, batch_first=True)\n",
    "        self.norm = nn.BatchNorm2d(ni)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n,c,h,w = x.shape\n",
    "        x = self.norm(x).view(n, c, -1).transpose(1, 2)\n",
    "        x = self.attn(x, x, x, need_weights=False)[0]\n",
    "        return x.transpose(1,2).reshape(n,c,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1318b9b6-d15c-4e70-8374-c33bb68e49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, ni, attn_chans, transpose=True):\n",
    "        super().__init__()\n",
    "        self.nheads = ni//attn_chans\n",
    "        self.scale = math.sqrt(ni/self.nheads)\n",
    "        self.norm = nn.LayerNorm(ni)\n",
    "        self.qkv = nn.Linear(ni, ni*3)\n",
    "        self.proj = nn.Linear(ni, ni)\n",
    "        self.t = transpose\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n,c,s = x.shape\n",
    "        if self.t: x = x.transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        x = self.qkv(x)\n",
    "        x = rearrange(x, 'n s (h d) -> (n h) s d', h=self.nheads)\n",
    "        q,k,v = torch.chunk(x, 3, dim=-1)\n",
    "        s = (q@k.transpose(1,2))/self.scale\n",
    "        x = s.softmax(dim=-1)@v\n",
    "        x = rearrange(x, '(n h) s d -> n s (h d)', h=self.nheads)\n",
    "        x = self.proj(x)\n",
    "        if self.t: x = x.transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6d02767-27f2-4a91-b1ef-39261d3875fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SelfAttention2D(SelfAttention):\n",
    "    def forward(self, x):\n",
    "        n,c,h,w = x.shape\n",
    "        return super().forward(x.view(n, c, -1)).reshape(n,c,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05b9f758-acf8-4470-839c-d8bc044f325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EmbResBlock(nn.Module):\n",
    "    def __init__(self, n_emb, ni, nf=None, ks=3, act=nn.SiLU, norm=nn.BatchNorm2d, attn_chans=0):\n",
    "        super().__init__()\n",
    "        if nf is None: nf = ni\n",
    "        self.emb_proj = nn.Linear(n_emb, nf*2)\n",
    "        self.conv1 = pre_conv(ni, nf, ks, act=act, norm=norm)\n",
    "        self.conv2 = pre_conv(nf, nf, ks, act=act, norm=norm)\n",
    "        self.idconv = fc.noop if ni==nf else nn.Conv2d(ni, nf, 1)\n",
    "        self.attn = False\n",
    "        if attn_chans: self.attn = SelfAttention2D(nf, attn_chans)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inp = x\n",
    "        x = self.conv1(x)\n",
    "        emb = self.emb_proj(F.silu(t))[:, :, None, None]\n",
    "        scale,shift = torch.chunk(emb, 2, dim=1)\n",
    "        x = x*(1+scale) + shift\n",
    "        x = self.conv2(x)\n",
    "        x = x + self.idconv(inp)\n",
    "        if self.attn: x = x + self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dfd646a-e21d-438f-8bf8-551217dcefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModule:\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        self.saved = super().forward(x, *args, **kwargs)\n",
    "        return self.saved\n",
    "\n",
    "class SavedEmbResBlock(SaveModule, EmbResBlock): pass\n",
    "class SavedConv2d(SaveModule, nn.Conv2d): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ff112c2-cf5e-4a83-aadf-0f9ca9ca2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, n_emb, ni, nf, add_down=True, num_layers=1, attn_chans=0):\n",
    "        super().__init__()\n",
    "        self.resnets = nn.ModuleList([SavedEmbResBlock(n_emb, ni if i==0 else nf, nf, attn_chans=attn_chans)\n",
    "                                      for i in range(num_layers)])\n",
    "        self.down = SavedConv2d(nf, nf, 3, stride=2, padding=1) if add_down else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.saved = []\n",
    "        for resnet in self.resnets: \n",
    "            x = resnet(x, t)\n",
    "            self.saved.append(resnet.saved)\n",
    "        x = self.down(x)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if isinstance(self.down, SavedConv2d): self.saved.append(self.down.saved)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e07e045-9c1f-4691-921c-ea1427a63433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, n_emb, ni, prev_nf, nf, add_up=True, num_layers=2, attn_chans=0):\n",
    "        super().__init__()\n",
    "        self.resnets = nn.ModuleList(\n",
    "            [EmbResBlock(n_emb, (prev_nf if i==0 else nf)+(ni if (i==num_layers-1) else nf), nf, attn_chans=attn_chans)\n",
    "            for i in range(num_layers)])\n",
    "        self.up = upsample(nf) if add_up else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t, ups):\n",
    "        for resnet in self.resnets: x = resnet(torch.cat([x, ups.pop()], dim=1), t)\n",
    "        return self.up(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b891bdd-237d-4374-967b-e8adcd8e1163",
   "metadata": {},
   "source": [
    "## Conditional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa431ed7-051b-4878-b393-e553b8dcf6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondUNetModel(nn.Module):\n",
    "    def __init__( self, n_classes, clip_emd_size, in_channels=3, out_channels=3, nfs=(224,448,672,896), num_layers=1):\n",
    "        super().__init__()\n",
    "        self.conv_in = nn.Conv2d(in_channels, nfs[0], kernel_size=3, padding=1)\n",
    "        self.n_temb = nf = nfs[0]\n",
    "        n_emb = nf*4\n",
    "        self.cond_emb = nn.Sequential(lin(clip_emd_size, n_emb, norm=nn.BatchNorm1d),\n",
    "                                     lin(n_emb, n_emb))\n",
    "        self.emb_mlp = nn.Sequential(lin(self.n_temb, n_emb, norm=nn.BatchNorm1d),\n",
    "                                     lin(n_emb, n_emb))\n",
    "        self.downs = nn.ModuleList()\n",
    "        for i in range(len(nfs)):\n",
    "            ni = nf\n",
    "            nf = nfs[i]\n",
    "            self.downs.append(DownBlock(n_emb, ni, nf, add_down=i!=len(nfs)-1, num_layers=num_layers))\n",
    "        self.mid_block = EmbResBlock(n_emb, nfs[-1])\n",
    "\n",
    "        rev_nfs = list(reversed(nfs))\n",
    "        nf = rev_nfs[0]\n",
    "        self.ups = nn.ModuleList()\n",
    "        for i in range(len(nfs)):\n",
    "            prev_nf = nf\n",
    "            nf = rev_nfs[i]\n",
    "            ni = rev_nfs[min(i+1, len(nfs)-1)]\n",
    "            self.ups.append(UpBlock(n_emb, ni, prev_nf, nf, add_up=i!=len(nfs)-1, num_layers=num_layers+1))\n",
    "        self.conv_out = pre_conv(nfs[0], out_channels, act=nn.SiLU, norm=nn.BatchNorm2d, bias=False)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x,t,c = inp\n",
    "        temb = timestep_embedding(t, self.n_temb)\n",
    "        cemb = self.cond_emb(c)\n",
    "        emb = self.emb_mlp(temb) + cemb\n",
    "        x = self.conv_in(x)\n",
    "        saved = [x]\n",
    "        for block in self.downs: x = block(x, emb)\n",
    "        #import pdb; pdb.set_trace() \n",
    "        saved += [p for o in self.downs for p in o.saved]\n",
    "        x = self.mid_block(x, emb)\n",
    "        for block in self.ups: x = block(x, emb, saved)\n",
    "        return self.conv_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3656ae8d-e491-4f78-b803-d671be4216c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 25\n",
    "opt_func = partial(optim.Adam, eps=1e-5)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched), MixedPrecision()]\n",
    "model = CondUNetModel(n_classes=200, clip_emd_size=512, in_channels=3, out_channels=3, nfs=(32,64,128,256), num_layers=2)\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae67c4-bd4a-4ca4-b5c9-e9d841197157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      8.00% [2/25 03:48&lt;43:52]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.163</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.094</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.081</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.076</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='114' class='' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.42% [114/313 00:39&lt;01:09 0.059]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 420x280 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b555b-172e-4ba8-b3d5-0a86e4d49e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'sd_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb28bf-e5ab-4100-9556-4b1e2116a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lded_model = torch.load('sd_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8972039-df7d-4d96-a3d3-bc49f7fe84ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(learn, 'sd_learn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139d731-f412-419c-b295-4449970f80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lded_learn = torch.load('sd_learn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast.ai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

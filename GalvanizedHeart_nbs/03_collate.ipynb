{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galvanized_heart/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from miniai.imports import *\n",
    "from miniai.datasets import *\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tiny Imagenet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"zh-plus/tiny-imagenet\"\n",
    "dsd = load_dataset(name).remove_columns(yl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(inp, out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(f\"x before layer: {x.shape}\")\n",
    "        x = self.layer(x)\n",
    "        print(f\"x after layer: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From ../03_collate_CLIP_verification.ipynb\n",
    "@inplace\n",
    "def transformi(b): \n",
    "    b[xl] = [TF.to_tensor(o) for o in b[xl]]\n",
    "\n",
    "def abar(t): return (t*math.pi/2).cos()**2\n",
    "def inv_abar(x): return x.sqrt().acos()*2/math.pi\n",
    "\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    x = clip_pro(images=x0, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "    c = clip_model.get_image_features(x[\"pixel_values\"])\n",
    "    n = len(x0)\n",
    "    t = torch.rand(n,).to(x0).clamp(0,0.999)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    abar_t = abar(t).reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = abar_t.sqrt()*x0 + (1-abar_t).sqrt()*ε\n",
    "    return (xt, t.to(device), c), ε\n",
    "\n",
    "\"\"\"def noisify(x0):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.rand(n,).to(x0).clamp(0,0.999)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    abar_t = abar(t).reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = abar_t.sqrt()*x0 + (1-abar_t).sqrt()*ε\n",
    "    return (xt, t.to(device)), ε\"\"\"\n",
    "\n",
    "def collate_sd(b): return noisify(default_collate(b)[xl])\n",
    "\n",
    "def dl_sd(ds): \n",
    "    return DataLoader(ds, batch_size=16, collate_fn=collate_sd, num_workers=0)\n",
    "\n",
    "tdsd = dsd.with_transform(transformi)\n",
    "dls = DataLoaders(dl_sd(tdsd['train']), dl_sd(tdsd['valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = dls.train\n",
    "b = next(iter(dl))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 25\n",
    "opt_func = partial(optim.Adam, eps=1e-5)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "cbs = [DeviceCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched), MixedPrecision()]\n",
    "model = TestModel(64,64)\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6250 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before layer: torch.Size([3, 64, 64])\n",
      "x after layer: torch.Size([3, 64, 64])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:238\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, gamma, max_mult, start_lr, max_epochs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;129m@fc\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlr_find\u001b[39m(\u001b[38;5;28mself\u001b[39m:Learner, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m, max_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, start_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLRFinderCB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_mult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:178\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epochs, train, valid, cbs, lr)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m cbs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs\u001b[38;5;241m.\u001b[39mremove(cb)\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:129\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:166\u001b[0m, in \u001b[0;36mLearner._fit\u001b[0;34m(self, train, valid)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, train, valid):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs:\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m train: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m valid: torch\u001b[38;5;241m.\u001b[39mno_grad()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_epoch)(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:161\u001b[0m, in \u001b[0;36mLearner.one_epoch\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mvalid\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:129\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:156\u001b[0m, in \u001b[0;36mLearner._one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_one_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:129\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:145\u001b[0m, in \u001b[0;36mLearner._one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_predict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:186\u001b[0m, in \u001b[0;36mLearner.callback\u001b[0;34m(self, method_nm)\u001b[0m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_nm): \u001b[43mrun_cbs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_nm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:35\u001b[0m, in \u001b[0;36mrun_cbs\u001b[0;34m(cbs, method_nm, learn)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(cbs, key\u001b[38;5;241m=\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     34\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cb, method_nm, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course22p2/miniai/learner.py:87\u001b[0m, in \u001b[0;36mTrainCB.get_loss\u001b[0;34m(self, learn)\u001b[0m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, learn): learn\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_inp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pro = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16)\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    x = clip_pro(images=x0, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "    c = clip_model.get_image_features(x[\"pixel_values\"])\n",
    "    n = len(x0)\n",
    "    t = torch.rand(n,).to(x0).clamp(0,0.999)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    abar_t = abar(t).reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = abar_t.sqrt()*x0 + (1-abar_t).sqrt()*ε\n",
    "    return (xt, t.to(device), c), ε\n",
    "\n",
    "x = torch.randn(16, 3, 64, 64).to(\"cuda\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[[ 8.4731e-02,  1.9793e+00,  9.7886e-01,  ...,  1.0126e+00,\n",
       "              6.7303e-01,  7.7479e-01],\n",
       "            [-8.9636e-03,  8.2476e-01,  2.0018e-01,  ...,  4.4483e-01,\n",
       "              7.5774e-01,  8.2832e-02],\n",
       "            [ 4.4587e-01,  1.5716e+00,  1.1063e+00,  ...,  7.2791e-01,\n",
       "              1.0862e+00, -1.3420e-02],\n",
       "            ...,\n",
       "            [ 7.9089e-01, -4.1945e-01,  2.3909e-01,  ..., -5.2777e-02,\n",
       "              5.1529e-01, -8.6123e-02],\n",
       "            [ 4.7922e-01,  2.7403e-02,  4.0663e-01,  ...,  1.9648e-01,\n",
       "              8.9855e-01,  2.1424e-02],\n",
       "            [-9.1558e-03,  4.3567e-01,  1.7748e-01,  ..., -5.4675e-01,\n",
       "             -3.1867e-01, -4.8917e-01]],\n",
       "  \n",
       "           [[-2.7990e-01,  7.8568e-01, -5.2200e-01,  ..., -2.0675e-01,\n",
       "              8.0967e-01,  1.0832e-01],\n",
       "            [ 9.1428e-01,  5.9087e-01,  1.5969e+00,  ...,  3.4134e-01,\n",
       "              2.1094e-01,  6.5804e-02],\n",
       "            [-5.0594e-01,  6.2912e-01,  6.7839e-01,  ...,  1.2645e+00,\n",
       "              6.6357e-01,  7.9468e-01],\n",
       "            ...,\n",
       "            [ 3.9059e-01,  6.4481e-01, -6.4690e-01,  ..., -2.4587e-01,\n",
       "              5.8154e-01,  8.0135e-01],\n",
       "            [ 1.0284e+00,  8.5427e-02, -4.4585e-02,  ..., -3.5042e-01,\n",
       "              5.0503e-01,  3.5893e-01],\n",
       "            [ 8.6083e-01,  1.4601e+00, -2.7576e-01,  ...,  1.0423e-01,\n",
       "             -3.0328e-02,  1.0165e+00]],\n",
       "  \n",
       "           [[ 8.4404e-01, -9.2914e-02,  9.4269e-02,  ...,  5.3891e-01,\n",
       "              3.5024e-01,  6.1600e-01],\n",
       "            [ 2.2334e-01,  4.4496e-01,  1.2891e+00,  ...,  1.7337e+00,\n",
       "              2.5911e+00,  6.4005e-01],\n",
       "            [-2.5452e-02,  1.5186e+00,  8.6870e-01,  ...,  1.2736e+00,\n",
       "              1.3448e+00,  1.8297e+00],\n",
       "            ...,\n",
       "            [ 5.5927e-01,  3.0122e-01, -8.3535e-02,  ..., -7.1933e-01,\n",
       "             -5.3138e-02,  2.7192e-01],\n",
       "            [ 6.9555e-01, -3.6580e-01,  7.1848e-01,  ..., -5.3335e-01,\n",
       "             -4.4497e-01,  4.9273e-02],\n",
       "            [-4.7290e-01,  7.2843e-01,  6.0680e-01,  ...,  3.7362e-01,\n",
       "              4.4825e-02,  4.0869e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 1.9106e-01, -2.0180e-01, -4.6109e-01,  ...,  2.3260e-01,\n",
       "              1.9209e-01,  9.8909e-02],\n",
       "            [ 2.0175e-01,  1.9352e-01, -3.3330e-01,  ...,  6.0644e-01,\n",
       "              8.2828e-01, -9.2921e-02],\n",
       "            [ 1.5289e-01,  6.5507e-01, -1.4703e-01,  ..., -3.7811e-01,\n",
       "              7.6203e-01,  2.7612e-01],\n",
       "            ...,\n",
       "            [ 1.2603e-01,  3.4136e-02,  1.7334e-01,  ...,  1.0019e+00,\n",
       "              3.5174e-01,  3.1279e-01],\n",
       "            [ 2.4376e-01,  3.4766e-01, -2.5106e-01,  ...,  4.0978e-01,\n",
       "              3.4154e-01,  7.1841e-01],\n",
       "            [-3.5762e-01, -4.9771e-01, -8.9660e-02,  ...,  6.9998e-01,\n",
       "             -5.5414e-01,  3.5795e-01]],\n",
       "  \n",
       "           [[-2.9513e-01, -1.5907e-01,  1.3422e-01,  ...,  4.7209e-01,\n",
       "              6.2574e-02,  1.1051e-01],\n",
       "            [-2.1768e-01,  3.2010e-01, -7.4678e-02,  ...,  2.1806e-01,\n",
       "             -1.3716e-01,  7.0364e-02],\n",
       "            [ 3.8337e-01,  7.5421e-01,  5.8487e-01,  ...,  4.4619e-01,\n",
       "              4.4095e-02,  5.5150e-01],\n",
       "            ...,\n",
       "            [-2.8853e-02,  8.2943e-02, -7.0603e-01,  ...,  5.4424e-02,\n",
       "              4.7655e-01,  6.4568e-01],\n",
       "            [-6.2789e-02, -2.0913e-01, -4.1615e-01,  ...,  4.7593e-01,\n",
       "              9.2880e-01,  5.3339e-01],\n",
       "            [ 1.4116e-01,  1.7560e-01, -4.7842e-01,  ...,  3.3601e-01,\n",
       "             -8.2798e-02,  9.8981e-01]],\n",
       "  \n",
       "           [[-2.2256e-01,  1.5537e-01, -6.9455e-02,  ..., -3.2596e-02,\n",
       "             -2.1288e-01,  5.9704e-01],\n",
       "            [ 1.9680e-01, -5.9194e-01,  2.6968e-01,  ...,  2.7325e-01,\n",
       "             -5.5275e-01,  5.9563e-01],\n",
       "            [ 1.1454e-01,  2.9240e-03, -2.3085e-01,  ..., -6.3407e-01,\n",
       "             -1.0099e-01, -1.4285e-01],\n",
       "            ...,\n",
       "            [ 1.0996e-01, -2.2168e-01,  4.8225e-01,  ...,  2.8960e-01,\n",
       "             -2.5144e-01, -7.4284e-01],\n",
       "            [-3.2061e-01,  1.9799e-01,  5.4344e-01,  ...,  3.7662e-01,\n",
       "              6.6624e-01, -1.7716e-01],\n",
       "            [ 1.8851e-01,  1.7369e-01,  6.7464e-02,  ...,  1.7902e-02,\n",
       "             -3.6170e-01,  3.4746e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 3.1984e-01,  1.0019e+00,  8.8654e-01,  ..., -3.5166e-01,\n",
       "              3.2018e-01,  1.5826e+00],\n",
       "            [ 1.5882e+00,  7.7112e-02,  5.6953e-01,  ...,  2.7173e-01,\n",
       "              1.3793e+00,  1.2396e+00],\n",
       "            [ 1.2049e+00, -7.9493e-01,  7.5621e-01,  ...,  3.7857e-01,\n",
       "             -4.3743e-01, -3.1532e-01],\n",
       "            ...,\n",
       "            [ 1.5396e+00,  1.4781e+00,  1.4323e-01,  ...,  4.0089e-01,\n",
       "              3.2193e-01,  1.1876e+00],\n",
       "            [-4.4018e-01, -6.0350e-01,  3.9314e-01,  ...,  1.1661e-01,\n",
       "              1.8997e+00,  2.0808e-01],\n",
       "            [ 8.2505e-01,  9.5504e-01,  7.1085e-01,  ...,  4.1859e-01,\n",
       "              1.1559e+00,  3.7294e-01]],\n",
       "  \n",
       "           [[ 2.2200e+00, -4.3838e-01, -3.1522e-01,  ...,  7.8457e-02,\n",
       "              1.4649e-01,  1.7483e+00],\n",
       "            [ 8.0294e-01,  1.3497e+00,  9.9109e-02,  ..., -5.7737e-01,\n",
       "             -2.3449e-01,  8.5667e-01],\n",
       "            [ 1.3658e+00, -1.1683e+00,  1.0990e+00,  ...,  8.8699e-01,\n",
       "              1.3937e+00,  1.1635e+00],\n",
       "            ...,\n",
       "            [ 7.1156e-01,  2.1775e+00,  6.9298e-01,  ..., -5.2659e-02,\n",
       "             -1.0194e+00,  1.3329e+00],\n",
       "            [ 1.5033e+00,  5.7895e-01,  1.2098e-02,  ...,  3.0027e-01,\n",
       "              5.5432e-01,  1.3658e-01],\n",
       "            [ 6.8123e-01,  7.1629e-01,  1.8455e+00,  ...,  1.9549e+00,\n",
       "              1.1006e+00,  3.5823e-01]],\n",
       "  \n",
       "           [[-5.2042e-01, -4.7553e-01,  1.2223e+00,  ...,  4.4423e-01,\n",
       "             -1.6906e+00,  2.3187e-01],\n",
       "            [ 2.3749e+00,  1.8624e+00,  5.5613e-01,  ..., -7.9817e-03,\n",
       "             -2.6802e-01,  6.9257e-01],\n",
       "            [ 8.3846e-02,  3.9355e-01,  9.0294e-01,  ...,  4.4888e-01,\n",
       "              1.6335e-01,  7.2484e-01],\n",
       "            ...,\n",
       "            [ 7.1712e-01, -3.0861e-01,  1.7209e+00,  ...,  1.1862e+00,\n",
       "              5.8923e-01,  9.3077e-01],\n",
       "            [ 1.0902e+00, -7.6771e-01,  2.0571e+00,  ...,  1.2494e+00,\n",
       "             -4.1749e-01,  9.1004e-01],\n",
       "            [ 9.1355e-01,  6.0116e-01,  1.2847e+00,  ...,  1.2333e+00,\n",
       "              1.6418e+00, -4.3202e-01]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-1.4862e+00,  8.8126e-01,  1.3040e+00,  ...,  1.9743e+00,\n",
       "              6.8291e-01,  1.2397e+00],\n",
       "            [-1.3054e+00,  1.9540e+00,  7.1232e-01,  ..., -9.4622e-01,\n",
       "             -1.0148e+00,  1.1606e+00],\n",
       "            [-5.8938e-01,  1.1204e+00, -1.3309e+00,  ...,  9.5817e-01,\n",
       "             -7.2186e-01,  7.2081e-01],\n",
       "            ...,\n",
       "            [-1.0221e+00, -2.6995e-01,  9.8185e-01,  ..., -5.3143e-01,\n",
       "              8.9069e-01,  5.1416e-02],\n",
       "            [ 1.3979e+00,  7.5371e-01, -9.5567e-01,  ..., -6.6542e-01,\n",
       "              5.2709e-01,  1.5051e+00],\n",
       "            [ 4.1650e-01,  6.1728e-01, -1.9496e+00,  ...,  8.1402e-02,\n",
       "              5.7981e-01,  1.7748e-02]],\n",
       "  \n",
       "           [[ 1.1144e+00,  9.9254e-01, -1.8000e+00,  ...,  4.8821e-01,\n",
       "              1.6913e-01, -8.6377e-01],\n",
       "            [-1.4541e-02, -7.5584e-01,  8.1411e-01,  ...,  9.2882e-01,\n",
       "             -9.4372e-01,  3.0598e-01],\n",
       "            [ 5.7271e-02,  1.9373e+00, -1.0252e+00,  ..., -1.7288e-02,\n",
       "              7.3984e-04,  3.8187e-01],\n",
       "            ...,\n",
       "            [ 1.4359e+00,  1.4743e-02, -4.7820e-01,  ..., -2.5579e-01,\n",
       "             -7.8817e-01, -8.7227e-01],\n",
       "            [ 2.0570e+00, -1.4469e+00,  8.9296e-01,  ..., -1.1625e+00,\n",
       "              6.0521e-02, -4.2588e-01],\n",
       "            [-8.3997e-01,  2.2021e-01, -1.3346e+00,  ..., -7.3270e-01,\n",
       "             -5.8411e-01, -8.9601e-01]],\n",
       "  \n",
       "           [[ 6.0259e-01,  1.7156e+00,  5.3763e-01,  ...,  1.8361e+00,\n",
       "              4.7814e-01,  1.0902e+00],\n",
       "            [-9.2722e-01,  1.2427e+00,  9.1539e-02,  ...,  5.1250e-02,\n",
       "             -3.4456e+00, -1.3814e+00],\n",
       "            [-1.5599e+00,  1.4092e+00,  1.5721e+00,  ...,  4.6501e-01,\n",
       "              1.5065e+00, -2.9227e-01],\n",
       "            ...,\n",
       "            [ 2.5944e-01, -3.5361e-02, -3.6554e-01,  ...,  2.7431e-01,\n",
       "              1.4818e-01, -1.1242e+00],\n",
       "            [ 3.4337e-01, -6.3314e-01,  1.0270e+00,  ...,  1.0547e+00,\n",
       "             -5.9202e-01, -2.3711e-01],\n",
       "            [ 9.4508e-01,  4.5553e-01,  1.1993e+00,  ..., -2.8464e-01,\n",
       "              1.9029e-01,  3.3677e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 9.1773e-01,  1.6443e+00, -3.8495e-01,  ...,  1.6827e+00,\n",
       "              5.2865e-01,  1.5740e-01],\n",
       "            [ 2.0506e-01,  6.7767e-02,  1.3495e-01,  ..., -2.1241e-03,\n",
       "             -6.2257e-01,  1.8816e-01],\n",
       "            [-1.6183e-01,  1.2888e+00,  1.4164e-01,  ...,  6.9646e-01,\n",
       "              4.4746e-01,  1.0166e+00],\n",
       "            ...,\n",
       "            [-6.6253e-03,  1.5472e-01,  1.0659e+00,  ..., -9.2117e-01,\n",
       "              8.0429e-01,  7.8070e-02],\n",
       "            [ 1.1324e+00, -1.3293e-02,  7.9611e-01,  ...,  8.2871e-01,\n",
       "              1.3754e+00,  8.2374e-01],\n",
       "            [ 6.3322e-01,  2.2334e-01,  5.9026e-01,  ...,  5.3740e-01,\n",
       "             -1.5399e-01, -6.8220e-01]],\n",
       "  \n",
       "           [[-5.5662e-01, -3.3714e-02, -3.7275e-01,  ..., -1.2738e+00,\n",
       "             -5.1455e-01,  3.9809e-01],\n",
       "            [-3.3365e-01,  8.3143e-01,  1.5347e-01,  ...,  3.6598e-01,\n",
       "              1.0319e+00, -9.9142e-01],\n",
       "            [ 2.9375e-01,  8.1151e-02,  5.0693e-01,  ...,  6.2489e-01,\n",
       "             -1.5876e-02,  2.0270e+00],\n",
       "            ...,\n",
       "            [-8.7431e-01,  1.1638e+00,  1.5095e+00,  ..., -5.7347e-01,\n",
       "             -9.4465e-01,  4.0669e-01],\n",
       "            [ 2.5575e-01,  9.3792e-01,  2.0556e+00,  ..., -2.0472e-01,\n",
       "             -8.9082e-01, -6.5538e-01],\n",
       "            [ 1.1446e+00,  1.8095e+00,  1.0107e+00,  ...,  3.5967e-01,\n",
       "             -9.1301e-01,  4.7656e-01]],\n",
       "  \n",
       "           [[ 1.4900e+00,  6.3281e-01, -5.1348e-01,  ...,  7.6908e-01,\n",
       "              7.8347e-01,  8.7274e-01],\n",
       "            [-1.7035e-01,  3.8545e-01,  5.8280e-01,  ...,  1.7523e+00,\n",
       "             -4.6355e-01,  2.6486e-01],\n",
       "            [-4.8164e-01,  5.1814e-01,  6.5716e-01,  ...,  7.3194e-01,\n",
       "              5.2099e-01,  3.7137e-01],\n",
       "            ...,\n",
       "            [-1.7856e-01,  1.0681e+00,  1.6867e+00,  ...,  4.2169e-02,\n",
       "              1.0365e+00,  4.6412e-01],\n",
       "            [ 7.3601e-01,  7.3062e-01, -4.9153e-01,  ..., -1.0805e+00,\n",
       "              2.7594e-01,  6.9807e-01],\n",
       "            [-9.9475e-01, -2.2106e-01,  1.3272e+00,  ...,  6.0445e-01,\n",
       "              5.8931e-01, -2.8774e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.3584e-01,  5.2756e-01,  5.9223e-01,  ...,  2.6826e-01,\n",
       "              4.3812e-01,  1.2691e-01],\n",
       "            [ 5.0148e-01,  4.2342e-01,  5.4941e-01,  ...,  4.5718e-01,\n",
       "              3.0755e-01,  2.2543e-01],\n",
       "            [ 5.7599e-01,  4.9634e-01,  5.4197e-01,  ...,  1.9292e-01,\n",
       "              2.9117e-01,  3.9773e-01],\n",
       "            ...,\n",
       "            [ 5.4304e-01,  4.6875e-01,  3.6665e-01,  ...,  3.0921e-02,\n",
       "              9.8152e-02,  1.0156e-01],\n",
       "            [ 5.3790e-01,  4.5732e-01,  4.2386e-01,  ..., -3.7380e-02,\n",
       "              8.8500e-02,  1.2484e-01],\n",
       "            [ 3.9035e-01,  3.4811e-01,  4.8198e-01,  ...,  3.1754e-02,\n",
       "              1.9778e-01,  3.2613e-02]],\n",
       "  \n",
       "           [[ 5.7768e-01,  5.8337e-01,  5.8608e-01,  ...,  3.3563e-01,\n",
       "              4.2026e-01,  2.5671e-01],\n",
       "            [ 5.3722e-01,  5.9313e-01,  5.8436e-01,  ...,  2.8084e-01,\n",
       "              4.6005e-01,  3.5290e-01],\n",
       "            [ 5.7428e-01,  5.0325e-01,  5.2192e-01,  ...,  3.3496e-01,\n",
       "              4.3585e-01,  4.1801e-01],\n",
       "            ...,\n",
       "            [ 4.8839e-01,  4.8249e-01,  5.5130e-01,  ...,  1.7886e-01,\n",
       "              2.4803e-01,  9.9197e-02],\n",
       "            [ 3.9172e-01,  4.9342e-01,  4.3806e-01,  ...,  1.0832e-01,\n",
       "              1.6252e-01,  1.1511e-01],\n",
       "            [ 4.6735e-01,  3.6404e-01,  2.6821e-01,  ...,  1.7932e-01,\n",
       "              8.5612e-02,  1.1085e-02]],\n",
       "  \n",
       "           [[ 5.7691e-01,  5.7607e-01,  6.0515e-01,  ...,  3.4807e-01,\n",
       "              4.0006e-01,  2.1402e-01],\n",
       "            [ 5.9574e-01,  6.1890e-01,  7.1796e-01,  ...,  3.3730e-01,\n",
       "              4.2071e-01,  3.0622e-01],\n",
       "            [ 6.3108e-01,  5.6839e-01,  5.7465e-01,  ...,  3.9997e-01,\n",
       "              3.8268e-01,  5.2133e-01],\n",
       "            ...,\n",
       "            [ 5.1154e-01,  4.8071e-01,  4.5813e-01,  ...,  2.1149e-02,\n",
       "              8.3191e-02,  6.7575e-03],\n",
       "            [ 4.6128e-01,  4.6801e-01,  4.6918e-01,  ...,  7.8981e-02,\n",
       "              4.5402e-02, -6.7410e-02],\n",
       "            [ 5.5985e-01,  4.3467e-01,  4.7438e-01,  ..., -2.0651e-02,\n",
       "              3.1525e-02,  3.7520e-02]]]], device='cuda:0'),\n",
       "  tensor([0.4037, 0.2331, 0.5407, 0.5821, 0.9537, 0.8854, 0.8480, 0.7409, 0.8034,\n",
       "          0.2310, 0.0058, 0.3984, 0.6196, 0.8171, 0.5105, 0.0384],\n",
       "         device='cuda:0'),\n",
       "  tensor([[-0.5352, -0.3667,  0.4419,  ...,  0.8882, -0.5420,  0.2529],\n",
       "          [-0.9185, -0.1493, -0.4043,  ..., -0.3147,  0.7974, -0.2839],\n",
       "          [-0.4580,  0.0479, -0.1232,  ...,  0.2681,  0.2546, -0.5220],\n",
       "          ...,\n",
       "          [-0.7344, -0.1710, -0.0673,  ...,  0.6313, -0.1753,  0.0972],\n",
       "          [-0.6968,  0.1082, -0.2710,  ..., -0.2542,  0.2135, -0.1881],\n",
       "          [-0.6558, -0.1094, -0.3035,  ...,  0.2325, -0.2595, -0.0898]],\n",
       "         device='cuda:0', dtype=torch.float16, grad_fn=<MmBackward0>)),\n",
       " tensor([[[[-1.2166e+00,  1.9809e+00,  3.2447e-01,  ...,  6.0007e-01,\n",
       "             2.1562e-02,  6.3052e-01],\n",
       "           [-1.3747e+00,  3.7717e-02, -9.7376e-01,  ..., -3.4226e-01,\n",
       "             2.0186e-01, -5.1601e-01],\n",
       "           [-6.0709e-01,  1.2929e+00,  5.0764e-01,  ...,  1.2486e-01,\n",
       "             7.5626e-01, -6.6246e-01],\n",
       "           ...,\n",
       "           [ 8.2832e-01, -1.2038e+00, -9.2335e-02,  ..., -5.4228e-01,\n",
       "             4.5380e-01, -6.4654e-01],\n",
       "           [ 3.3429e-01, -4.2828e-01,  2.1176e-01,  ..., -1.2692e-01,\n",
       "             1.1060e+00, -4.2771e-01],\n",
       "           [-5.0065e-01,  2.5011e-01, -1.9631e-01,  ..., -1.4346e+00,\n",
       "            -9.4838e-01, -1.2095e+00]],\n",
       " \n",
       "          [[-1.1975e+00,  5.9025e-01, -1.6594e+00,  ..., -1.6126e+00,\n",
       "             8.1565e-02, -6.8627e-01],\n",
       "           [ 8.7127e-01,  3.1478e-01,  1.9648e+00,  ..., -6.5555e-01,\n",
       "            -8.9162e-01, -7.3669e-01],\n",
       "           [-1.5257e+00,  3.7401e-01,  4.2517e-01,  ...,  8.9192e-01,\n",
       "            -1.2769e-01,  5.1480e-01],\n",
       "           ...,\n",
       "           [ 8.7372e-03,  4.5381e-01, -1.7103e+00,  ..., -8.0952e-01,\n",
       "             6.2427e-01,  9.0994e-01],\n",
       "           [ 1.1119e+00, -4.6897e-01, -6.7241e-01,  ..., -9.9131e-01,\n",
       "             5.0048e-01,  2.0057e-01],\n",
       "           [ 8.1839e-01,  1.8298e+00, -1.0839e+00,  ..., -2.7729e-01,\n",
       "            -4.0308e-01,  1.3903e+00]],\n",
       " \n",
       "          [[ 3.9550e-01, -1.1805e+00, -9.0192e-01,  ..., -3.4342e-01,\n",
       "            -6.8851e-01,  1.8124e-01],\n",
       "           [-6.3076e-01, -2.5672e-01,  1.1413e+00,  ...,  1.6997e+00,\n",
       "             3.1414e+00,  2.5382e-01],\n",
       "           [-1.1146e+00,  1.4913e+00,  3.8381e-01,  ...,  9.2324e-01,\n",
       "             1.0488e+00,  2.2937e+00],\n",
       "           ...,\n",
       "           [ 5.6536e-01,  1.2983e-01, -5.1421e-01,  ..., -1.5126e+00,\n",
       "            -3.5094e-01,  1.1236e-01],\n",
       "           [ 8.2201e-01, -9.7461e-01,  8.6073e-01,  ..., -1.2041e+00,\n",
       "            -1.0069e+00, -2.2608e-01],\n",
       "           [-1.1607e+00,  8.5619e-01,  6.5091e-01,  ...,  2.7335e-01,\n",
       "            -1.8027e-01,  4.6051e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2909e-01, -7.5791e-01, -1.5230e+00,  ...,  1.6899e-01,\n",
       "             1.4936e-02, -2.6575e-01],\n",
       "           [ 3.0782e-01,  3.1551e-01, -1.1661e+00,  ...,  1.2233e+00,\n",
       "             1.8122e+00, -7.7083e-01],\n",
       "           [ 1.4066e-01,  1.5841e+00, -6.3562e-01,  ..., -1.5469e+00,\n",
       "             1.6169e+00,  2.4963e-01],\n",
       "           ...,\n",
       "           [ 3.5197e-01,  8.5111e-02,  4.5344e-01,  ...,  2.0209e+00,\n",
       "             5.9377e-01,  3.6226e-01],\n",
       "           [ 6.8079e-01,  9.6073e-01, -7.2162e-01,  ...,  1.6275e-01,\n",
       "             1.3579e-01,  1.2701e+00],\n",
       "           [-1.0192e+00, -1.3900e+00, -2.5041e-01,  ...,  1.4130e+00,\n",
       "            -2.0692e+00,  4.7816e-01]],\n",
       " \n",
       "          [[-1.1617e+00, -7.7149e-01,  5.7848e-02,  ...,  8.7875e-01,\n",
       "            -2.9565e-01, -1.8223e-01],\n",
       "           [-9.8632e-01,  5.4630e-01, -5.2558e-01,  ...,  1.7950e-01,\n",
       "            -8.3302e-01, -2.6366e-01],\n",
       "           [ 6.6166e-01,  1.7382e+00,  1.3369e+00,  ...,  7.9618e-01,\n",
       "            -3.3703e-01,  1.0698e+00],\n",
       "           ...,\n",
       "           [-1.0104e-01,  2.0097e-01, -2.0127e+00,  ..., -4.4112e-01,\n",
       "             1.1162e+00,  1.4658e+00],\n",
       "           [-2.0604e-01, -6.2498e-01, -1.2031e+00,  ...,  5.1112e-01,\n",
       "             1.9395e+00,  9.0679e-01],\n",
       "           [ 3.4310e-01,  4.5974e-01, -1.3464e+00,  ...,  5.4983e-01,\n",
       "            -5.9939e-01,  2.3860e+00]],\n",
       " \n",
       "          [[-6.9317e-01,  3.7256e-01, -2.9624e-01,  ..., -2.3420e-01,\n",
       "            -7.5817e-01,  1.4834e+00],\n",
       "           [ 4.1670e-01, -1.7555e+00,  6.5092e-01,  ...,  6.3021e-01,\n",
       "            -1.6971e+00,  1.5101e+00],\n",
       "           [ 1.3582e-01, -1.3500e-01, -7.5721e-01,  ..., -1.9243e+00,\n",
       "            -4.4568e-01, -5.7280e-01],\n",
       "           ...,\n",
       "           [ 3.0710e-01, -6.1912e-01,  1.3468e+00,  ...,  6.0430e-01,\n",
       "            -7.0224e-01, -2.0747e+00],\n",
       "           [-8.9543e-01,  5.5295e-01,  1.5177e+00,  ...,  5.7120e-01,\n",
       "             1.5744e+00, -6.7884e-01],\n",
       "           [ 5.2649e-01,  4.8509e-01,  1.8842e-01,  ..., -4.2040e-02,\n",
       "            -1.0409e+00,  9.4995e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1991e-02,  1.0273e+00,  9.0480e-01,  ..., -7.8925e-01,\n",
       "            -6.3460e-02,  1.7387e+00],\n",
       "           [ 1.8186e+00, -3.1476e-01,  4.7910e-01,  ..., -1.0730e-01,\n",
       "             1.4024e+00,  1.2612e+00],\n",
       "           [ 1.4427e+00, -1.3003e+00,  7.9676e-01,  ..., -2.1686e-01,\n",
       "            -9.3454e-01, -8.3401e-01],\n",
       "           ...,\n",
       "           [ 1.4365e+00,  1.4063e+00, -3.7505e-01,  ..., -1.9058e-01,\n",
       "            -2.8885e-01,  8.6759e-01],\n",
       "           [-1.1107e+00, -1.3144e+00, -7.6930e-03,  ..., -5.6231e-01,\n",
       "             1.8195e+00, -4.3013e-01],\n",
       "           [ 6.2623e-01,  7.3037e-01,  3.9133e-01,  ..., -1.4630e-01,\n",
       "             8.4264e-01, -1.9675e-01]],\n",
       " \n",
       "          [[ 2.5290e+00, -9.0475e-01, -7.0966e-01,  ..., -2.4397e-01,\n",
       "            -3.2240e-01,  1.9318e+00],\n",
       "           [ 7.5895e-01,  1.3664e+00, -1.6126e-01,  ..., -1.2727e+00,\n",
       "            -7.7465e-01,  7.1665e-01],\n",
       "           [ 1.6433e+00, -1.8113e+00,  1.2395e+00,  ...,  4.1893e-01,\n",
       "             1.4699e+00,  1.0943e+00],\n",
       "           ...,\n",
       "           [ 2.4392e-01,  2.2516e+00,  2.8127e-01,  ..., -9.0163e-01,\n",
       "            -2.1824e+00,  9.5414e-01],\n",
       "           [ 1.3779e+00,  1.7079e-01, -5.8766e-01,  ..., -4.2466e-01,\n",
       "            -7.9370e-02, -6.3232e-01],\n",
       "           [ 3.3462e-01,  3.2267e-01,  1.8301e+00,  ...,  1.7930e+00,\n",
       "             6.6199e-01, -3.2330e-01]],\n",
       " \n",
       "          [[-1.1313e+00, -9.6458e-01,  1.3279e+00,  ...,  2.3631e-01,\n",
       "            -2.7762e+00, -9.4837e-02],\n",
       "           [ 2.8424e+00,  2.0390e+00,  4.3711e-01,  ..., -5.1780e-01,\n",
       "            -8.2621e-01,  4.9464e-01],\n",
       "           [-7.4632e-02,  2.5852e-01,  9.6803e-01,  ..., -1.6461e-01,\n",
       "            -1.7229e-01,  5.1001e-01],\n",
       "           ...,\n",
       "           [ 2.5477e-01, -1.0493e+00,  1.6608e+00,  ...,  7.3122e-01,\n",
       "            -5.7030e-02,  4.0133e-01],\n",
       "           [ 8.3453e-01, -1.6125e+00,  2.1534e+00,  ...,  8.2225e-01,\n",
       "            -1.3910e+00,  3.8062e-01],\n",
       "           [ 6.5095e-01,  1.7967e-01,  1.1004e+00,  ...,  8.1460e-01,\n",
       "             1.3657e+00, -1.3931e+00]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.7039e+00,  7.5787e-01,  1.1917e+00,  ...,  1.8119e+00,\n",
       "             4.5255e-01,  1.0366e+00],\n",
       "           [-1.5141e+00,  1.8799e+00,  5.7938e-01,  ..., -1.2230e+00,\n",
       "            -1.2934e+00,  9.8197e-01],\n",
       "           [-7.6983e-01,  1.0095e+00, -1.5500e+00,  ...,  7.6275e-01,\n",
       "            -9.9257e-01,  5.0597e-01],\n",
       "           ...,\n",
       "           [-1.0820e+00, -3.0119e-01,  1.0111e+00,  ..., -6.8508e-01,\n",
       "             8.1636e-01, -4.3719e-02],\n",
       "           [ 1.4391e+00,  7.6739e-01, -9.9883e-01,  ..., -7.8424e-01,\n",
       "             4.5808e-01,  1.4929e+00],\n",
       "           [ 4.3082e-01,  6.3670e-01, -2.0434e+00,  ...,  1.5358e-02,\n",
       "             5.1190e-01, -6.0287e-02]],\n",
       " \n",
       "          [[ 1.0253e+00,  8.9128e-01, -2.0275e+00,  ...,  2.9008e-01,\n",
       "            -5.0754e-02, -1.1243e+00],\n",
       "           [-1.5073e-01, -9.2835e-01,  7.0290e-01,  ...,  7.5994e-01,\n",
       "            -1.1868e+00,  1.2323e-01],\n",
       "           [-7.8170e-02,  1.8787e+00, -1.2139e+00,  ..., -2.2660e-01,\n",
       "            -2.0664e-01,  1.8499e-01],\n",
       "           ...,\n",
       "           [ 1.4811e+00, -4.3255e-03, -5.1138e-01,  ..., -3.7448e-01,\n",
       "            -9.0528e-01, -9.7907e-01],\n",
       "           [ 2.1287e+00, -1.5249e+00,  9.2881e-01,  ..., -1.2794e+00,\n",
       "             5.3677e-04, -4.9158e-01],\n",
       "           [-8.7703e-01,  2.2499e-01, -1.4020e+00,  ..., -8.1037e-01,\n",
       "            -6.7280e-01, -9.8413e-01]],\n",
       " \n",
       "          [[ 4.9741e-01,  1.6510e+00,  4.1576e-01,  ...,  1.7233e+00,\n",
       "             2.9695e-01,  9.4093e-01],\n",
       "           [-1.0966e+00,  1.1614e+00, -4.4754e-02,  ..., -1.2732e-01,\n",
       "            -3.7702e+00, -1.6085e+00],\n",
       "           [-1.7587e+00,  1.3339e+00,  1.5002e+00,  ...,  3.0412e-01,\n",
       "             1.3890e+00, -4.9015e-01],\n",
       "           ...,\n",
       "           [ 2.6821e-01, -4.2666e-02, -3.8232e-01,  ...,  1.8870e-01,\n",
       "             7.9194e-02, -1.2302e+00],\n",
       "           [ 3.5689e-01, -6.6252e-01,  1.0709e+00,  ...,  1.0429e+00,\n",
       "            -6.7179e-01, -2.8664e-01],\n",
       "           [ 9.8547e-01,  4.7500e-01,  1.2505e+00,  ..., -3.3504e-01,\n",
       "             1.4280e-01,  3.0945e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 9.9244e-01,  2.0224e+00, -8.0507e-01,  ...,  1.7950e+00,\n",
       "             4.4723e-01, -1.4525e-01],\n",
       "           [ 7.5463e-04, -1.8650e-01, -1.0439e-01,  ..., -5.1143e-01,\n",
       "            -1.2533e+00, -2.2767e-01],\n",
       "           [-4.6045e-01,  1.5315e+00, -7.6122e-02,  ...,  5.6310e-01,\n",
       "             2.3939e-01,  9.8201e-01],\n",
       "           ...,\n",
       "           [-7.2639e-01, -4.8290e-01,  7.8119e-01,  ..., -1.6802e+00,\n",
       "             7.9664e-01, -4.9470e-01],\n",
       "           [ 7.1815e-01, -8.7227e-01,  3.2232e-01,  ...,  8.0405e-01,\n",
       "             1.2270e+00,  8.2749e-01],\n",
       "           [ 1.1842e-01, -5.1264e-01,  3.9669e-02,  ...,  6.4154e-01,\n",
       "            -6.8481e-01, -1.4008e+00]],\n",
       " \n",
       "          [[-1.0288e+00, -2.8218e-01, -7.6533e-01,  ..., -2.4403e+00,\n",
       "            -1.1182e+00,  7.2038e-02],\n",
       "           [-7.1851e-01,  8.9891e-01, -5.5864e-02,  ..., -1.0166e-01,\n",
       "             9.5012e-01, -1.9677e+00],\n",
       "           [ 1.9625e-01, -1.2614e-01,  4.5496e-01,  ...,  3.9142e-01,\n",
       "            -4.6605e-01,  2.3235e+00],\n",
       "           ...,\n",
       "           [-1.9072e+00,  9.4013e-01,  1.4288e+00,  ..., -1.1319e+00,\n",
       "            -1.5763e+00,  2.3292e-02],\n",
       "           [-4.6375e-01,  4.8170e-01,  2.1128e+00,  ..., -5.9222e-01,\n",
       "            -1.8847e+00, -1.1890e+00],\n",
       "           [ 8.6791e-01,  1.7325e+00,  6.6650e-01,  ...,  4.2459e-01,\n",
       "            -1.7030e+00,  2.4953e-01]],\n",
       " \n",
       "          [[ 1.7622e+00,  5.9596e-01, -9.9909e-01,  ...,  5.4274e-01,\n",
       "             8.3217e-01,  8.8809e-01],\n",
       "           [-5.4820e-01,  2.3278e-01,  5.0361e-01,  ...,  1.9527e+00,\n",
       "            -9.9033e-01, -7.9202e-02],\n",
       "           [-9.2823e-01,  4.4399e-01,  6.2606e-01,  ...,  6.4663e-01,\n",
       "             3.9103e-01,  1.4109e-01],\n",
       "           ...,\n",
       "           [-9.1631e-01,  8.2983e-01,  1.6869e+00,  ..., -2.3730e-01,\n",
       "             1.2298e+00,  1.5254e-01],\n",
       "           [ 2.0833e-01,  2.0083e-01, -1.4353e+00,  ..., -1.7881e+00,\n",
       "            -2.3833e-01,  7.1714e-01],\n",
       "           [-2.1128e+00, -1.0969e+00,  1.0842e+00,  ...,  7.7658e-01,\n",
       "             3.9503e-01, -8.0640e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.1308e-01, -5.3468e-01, -1.1085e-01,  ..., -1.7851e+00,\n",
       "             1.3597e+00, -2.1172e+00],\n",
       "           [-1.2286e-01, -2.4585e+00, -6.9183e-01,  ...,  7.6630e-01,\n",
       "            -1.1329e+00, -4.8152e-01],\n",
       "           [-3.1559e-01, -5.9798e-01,  2.8950e-01,  ..., -2.2561e+00,\n",
       "            -1.1448e+00,  6.8919e-01],\n",
       "           ...,\n",
       "           [ 1.6070e+00,  3.7360e-01, -1.3213e+00,  ..., -1.2413e+00,\n",
       "             4.8252e-03,  2.5629e-01],\n",
       "           [ 1.5865e+00,  2.4885e-01, -3.0669e-01,  ..., -2.3102e+00,\n",
       "            -1.5540e-01,  7.7275e-01],\n",
       "           [-8.6300e-01, -1.5643e+00,  6.5825e-01,  ..., -1.0325e+00,\n",
       "             1.8538e+00, -6.2831e-01]],\n",
       " \n",
       "          [[-3.5249e-01,  3.9191e-01, -4.0799e-01,  ...,  7.6305e-01,\n",
       "             1.0632e+00, -7.4212e-01],\n",
       "           [ 4.7047e-01,  3.5896e-01, -3.0661e-01,  ..., -8.6139e-01,\n",
       "             1.3339e+00,  7.8977e-01],\n",
       "           [-2.1392e-01, -4.8335e-01, -1.7341e-01,  ...,  1.0768e+00,\n",
       "             1.1270e+00,  2.4607e-01],\n",
       "           ...,\n",
       "           [ 8.9454e-01,  7.9660e-01,  1.9390e+00,  ...,  6.9487e-01,\n",
       "             1.9732e+00, -3.0274e-01],\n",
       "           [-7.1033e-01,  9.7801e-01,  5.9121e-02,  ..., -4.1129e-01,\n",
       "             5.5347e-01, -3.8565e-02],\n",
       "           [ 5.4522e-01, -1.1698e+00, -2.7607e+00,  ...,  8.9744e-01,\n",
       "            -6.5824e-01, -1.6355e+00]],\n",
       " \n",
       "          [[-1.1450e+00, -3.7926e-01, -6.7620e-01,  ...,  8.3961e-01,\n",
       "             7.7966e-02, -2.3606e+00],\n",
       "           [ 6.6224e-01,  6.8932e-03,  1.3265e+00,  ...,  1.4092e-01,\n",
       "             3.5582e-01, -5.0510e-01],\n",
       "           [-1.8075e-01, -1.8179e-01, -7.7883e-02,  ...,  2.6109e+00,\n",
       "             4.3944e-01,  2.0913e+00],\n",
       "           ...,\n",
       "           [ 1.7419e-01, -3.3770e-01, -7.1259e-01,  ..., -4.2872e-01,\n",
       "             7.3123e-01, -3.4271e-01],\n",
       "           [-4.6525e-01, -3.5361e-01, -3.3416e-01,  ...,  5.9634e-01,\n",
       "             1.0388e-01, -1.5090e+00],\n",
       "           [ 1.1711e+00, -9.0707e-01, -2.4773e-01,  ..., -9.2769e-01,\n",
       "             3.4787e-03,  3.6294e-01]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_b = noisify(b.to(\"cuda\"))\n",
    "n_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n_b[0]), len(n_b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 64, 64]), torch.Size([16]), torch.Size([16, 768]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_b[0][0].shape,n_b[0][1].shape,n_b[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(x)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(n,).to(x).clamp(0,0.999)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = torch.randn(x.shape)\n",
    "eps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abar_t = abar(t)\n",
    "print(abar_t.shape)\n",
    "abar_t = abar_t.reshape(-1,1,1,1)\n",
    "abar_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = abar_t.sqrt()*x + (1-abar_t).sqrt()*eps\n",
    "xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required functions for loading pickled DataLoaders\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "def transform(batch):\n",
    "    print(\"Transforming batch\")\n",
    "    transformed = [TF.to_tensor(o) for o in batch[xl]] # This gives \"TypeError: only integer tensors of a single element can be converted to an index\"\n",
    "    print(\"Finished transforming\")\n",
    "    return transformed\n",
    "\n",
    "def abar(t): \n",
    "    return (t*math.pi/2).cos()**2\n",
    "\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.rand(n,).to(x0).clamp(0,0.999)\n",
    "    eps = torch.randn(x0.shape, device=device)\n",
    "    abar_t = abar(t).reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = abar_t.sqrt()*x0 + (1-abar_t).sqrt()*eps\n",
    "    return (xt, t.to(device)), eps\n",
    "\n",
    "def collate_clip(batch):\n",
    "    print(\"Collate clip\")\n",
    "    batch = default_collate(batch)\n",
    "    print(\"After default\")\n",
    "    batch = batch[\"image\"]\n",
    "    print(batch)\n",
    "    print(type(batch))\n",
    "    print(len(batch))\n",
    "    return\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=batch[\"image\"], return_tensors=\"pt\", do_rescale=False)\n",
    "        print(\"After CLIP processing\")\n",
    "        image_input = inputs[\"pixel_values\"]\n",
    "        image_features = model.get_image_features(image_input)\n",
    "    print(\"After CLIP embs\")\n",
    "    (xt, t), eps = noisify(batch)\n",
    "    print(\"After noisify\")\n",
    "    return (xt, t, image_features), eps\n",
    "\n",
    "def dl_ddpm(ds): \n",
    "    return DataLoader(ds, batch_size=16, collate_fn=collate_clip, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "def PIL_to_tensor(batch):\n",
    "    print(batch)\n",
    "    batch[\"image\"] = [transform(image) for image in batch[\"image\"]]\n",
    "    print(batch)\n",
    "    return batch\n",
    "\n",
    "tdsd = dsd.map(PIL_to_tensor, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl_ddpm(tdsd['train']), dl_ddpm(tdsd['valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collate clip\n",
      "After default\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dl \u001b[38;5;241m=\u001b[39m dls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m----> 2\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m b\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m, in \u001b[0;36mcollate_clip\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m batch \u001b[38;5;241m=\u001b[39m default_collate(batch)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter default\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(batch))\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "dl = dls.train\n",
    "b = next(iter(dl))\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
